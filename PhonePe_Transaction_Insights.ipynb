{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "bn_IUdTipZyH",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "Iwf50b-R2tYG",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "1UUpS68QDMuG",
        "P1XJ9OREExlT",
        "TIqpNgepFxVj",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasu-Rocks/AI-ML-Project/blob/main/PhonePe_Transaction_Insights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - PhonePe Transaction Insights\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - ML/Random Forest/Gradient Boosting/Linear Regression\n",
        "##### **Team Member -** Vasu Goyal"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project analyzes the PhonePe Pulse dataset to understand digital payment trends across India.\n",
        "The analysis covers transaction dynamics, user engagement patterns, device usage, insurance penetration,\n",
        "and regional market expansion opportunities. Using aggregated transaction data, user demographics,\n",
        "and insurance metrics from 2018-2024, we explore five key business case studies:\n",
        "\n",
        "1. **Transaction Dynamics Analysis** - Understanding payment category trends across states and quarters\n",
        "2. **Device Dominance & User Engagement** - Analyzing device brand preferences and app usage patterns  \n",
        "3. **Insurance Penetration Analysis** - Identifying growth opportunities in insurance adoption\n",
        "4. **Market Expansion Strategy** - Mapping regional transaction patterns for expansion planning\n",
        "5. **User Growth & Engagement** - Analyzing user registration and retention patterns\n",
        "\n",
        "The dataset includes JSON files organized into aggregated, map, and top-level data structures covering\n",
        "transactions, users, and insurance metrics. Through comprehensive EDA, statistical testing, and machine\n",
        "learning models, we derive actionable insights for PhonePe's strategic decision-making in product\n",
        "development, marketing allocation, and regional expansion strategies."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This analysis aims to provide data-driven insights to optimize marketing spend, improve product\n",
        "offerings, enhance user experience, and drive sustainable growth across all business verticals."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import sqlite3\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Statistical libraries\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu\n",
        "\n",
        "# Machine Learning libraries\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "# Mount Google Drive to access files (for Colab users)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up paths for data access\n",
        "ROOT_DIR = Path(\"/content/drive/MyDrive\")\n",
        "CACHE_DIR = Path(\"cache\")\n",
        "CACHE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "def load_transaction_data():\n",
        "    # Load all transaction JSON files and extract data\n",
        "    transactions = []\n",
        "    pattern = str(ROOT_DIR / \"data\" / \"aggregated\" / \"transaction\" / \"country\" / \"india\" / \"*\" / \"*.json\")\n",
        "    for file_path in glob.glob(pattern):\n",
        "        try:\n",
        "            year = int(Path(file_path).parent.name)\n",
        "            quarter = int(Path(file_path).stem)\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "            # Only process if transaction data exists\n",
        "            if 'data' in data and 'transactionData' in data['data']:\n",
        "                for transaction in data['data']['transactionData']:\n",
        "                    transactions.append({\n",
        "                        'year': year,\n",
        "                        'quarter': quarter,\n",
        "                        'category': transaction['name'],\n",
        "                        'count': transaction['paymentInstruments'][0]['count'],\n",
        "                        'amount': transaction['paymentInstruments'][0]['amount']\n",
        "                    })\n",
        "        except Exception as e:\n",
        "            # Log errors but keep loading other files\n",
        "            logging.error(f\"Error processing {file_path}: {e}\")\n",
        "            continue\n",
        "    return pd.DataFrame(transactions)\n",
        "\n",
        "def load_user_data():\n",
        "    # Load user data, including device-wise info\n",
        "    users = []\n",
        "    pattern = str(ROOT_DIR / \"data\" / \"aggregated\" / \"user\" / \"country\" / \"india\" / \"*\" / \"*.json\")\n",
        "    for file_path in glob.glob(pattern):\n",
        "        try:\n",
        "            year = int(Path(file_path).parent.name)\n",
        "            quarter = int(Path(file_path).stem)\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "            if 'data' in data:\n",
        "                # Add overall user stats\n",
        "                if 'aggregated' in data['data']:\n",
        "                    agg_data = data['data']['aggregated']\n",
        "                    users.append({\n",
        "                        'year': year,\n",
        "                        'quarter': quarter,\n",
        "                        'type': 'aggregated',\n",
        "                        'brand': 'Total',\n",
        "                        'registered_users': agg_data.get('registeredUsers', 0),\n",
        "                        'app_opens': agg_data.get('appOpens', 0),\n",
        "                        'percentage': 1.0\n",
        "                    })\n",
        "                # Add device-wise user stats if available\n",
        "                users_by_device = data['data'].get('usersByDevice')\n",
        "                if isinstance(users_by_device, list):\n",
        "                    for device in users_by_device:\n",
        "                        users.append({\n",
        "                            'year': year,\n",
        "                            'quarter': quarter,\n",
        "                            'type': 'device',\n",
        "                            'brand': device['brand'],\n",
        "                            'registered_users': device['count'],\n",
        "                            'app_opens': 0,\n",
        "                            'percentage': device['percentage']\n",
        "                        })\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing {file_path}: {e}\")\n",
        "            continue\n",
        "    return pd.DataFrame(users)\n",
        "\n",
        "def load_insurance_data():\n",
        "    # Load insurance transaction data\n",
        "    insurance = []\n",
        "    pattern = str(ROOT_DIR / \"data\" / \"aggregated\" / \"insurance\" / \"country\" / \"india\" / \"*\" / \"*.json\")\n",
        "    for file_path in glob.glob(pattern):\n",
        "        try:\n",
        "            year = int(Path(file_path).parent.name)\n",
        "            quarter = int(Path(file_path).stem)\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "            if 'data' in data and 'transactionData' in data['data']:\n",
        "                for transaction in data['data']['transactionData']:\n",
        "                    insurance.append({\n",
        "                        'year': year,\n",
        "                        'quarter': quarter,\n",
        "                        'category': transaction['name'],\n",
        "                        'count': transaction['paymentInstruments'][0]['count'],\n",
        "                        'amount': transaction['paymentInstruments'][0]['amount']\n",
        "                    })\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing {file_path}: {e}\")\n",
        "            continue\n",
        "    return pd.DataFrame(insurance)\n",
        "\n",
        "# Load datasets for analysis\n",
        "transaction_df = load_transaction_data()\n",
        "user_df = load_user_data()\n",
        "insurance_df = load_insurance_data()\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# Dataset First Look\n",
        "print(\"Transaction Data Sample:\")\n",
        "print(transaction_df.head())\n",
        "print(f\"\\nTransaction Data Shape: {transaction_df.shape}\")\n",
        "\n",
        "print(\"\\nUser Data Sample:\")\n",
        "print(user_df.head())\n",
        "print(f\"\\nUser Data Shape: {user_df.shape}\")\n",
        "\n",
        "print(\"\\nInsurance Data Sample:\")\n",
        "print(insurance_df.head())\n",
        "print(f\"\\nInsurance Data Shape: {insurance_df.shape}\")\n",
        "\n",
        "### Dataset Rows & Columns count\n",
        "\n",
        "# Dataset Rows & Columns count\n",
        "print(f\"Transaction Dataset: {transaction_df.shape[0]} rows, {transaction_df.shape[1]} columns\")\n",
        "print(f\"User Dataset: {user_df.shape[0]} rows, {user_df.shape[1]} columns\")\n",
        "print(f\"Insurance Dataset: {insurance_df.shape[0]} rows, {insurance_df.shape[1]} columns\")"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f\"Transaction Dataset: {transaction_df.shape[0]} rows, {transaction_df.shape[1]} columns\")\n",
        "print(f\"User Dataset: {user_df.shape[0]} rows, {user_df.shape[1]} columns\")\n",
        "print(f\"Insurance Dataset: {insurance_df.shape[0]} rows, {insurance_df.shape[1]} columns\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "print(\"Transaction Dataset Info:\")\n",
        "print(transaction_df.info())\n",
        "print(\"\\nUser Dataset Info:\")\n",
        "print(user_df.info())\n",
        "print(\"\\nInsurance Dataset Info:\")\n",
        "print(insurance_df.info())"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Transaction duplicates: {transaction_df.duplicated().sum()}\")\n",
        "print(f\"User duplicates: {user_df.duplicated().sum()}\")\n",
        "print(f\"Insurance duplicates: {insurance_df.duplicated().sum()}\")"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"Transaction Dataset Missing Values:\")\n",
        "print(transaction_df.isnull().sum())\n",
        "print(\"\\nUser Dataset Missing Values:\")\n",
        "print(user_df.isnull().sum())\n",
        "print(\"\\nInsurance Dataset Missing Values:\")\n",
        "print(insurance_df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.heatmap(transaction_df.isnull(), yticklabels=False, cbar=True)\n",
        "plt.title('Transaction Data Missing Values')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.heatmap(user_df.isnull(), yticklabels=False, cbar=True)\n",
        "plt.title('User Data Missing Values')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.heatmap(insurance_df.isnull(), yticklabels=False, cbar=True)\n",
        "plt.title('Insurance Data Missing Values')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the initial exploration of the PhonePe Pulse dataset, here are the key insights:\n",
        "\n",
        "1. **Data Structure**: The dataset contains three main data types - transactions, users, and insurance data,\n",
        "   spanning multiple years and quarters from 2018-2024.\n",
        "\n",
        "2. **Transaction Data**: Contains payment category information with count and amount metrics across different\n",
        "   time periods. Main categories include recharge & bill payments, peer-to-peer payments, merchant payments, etc.\n",
        "\n",
        "3. **User Data**: Includes both aggregated user statistics (total registered users, app opens) and device-wise\n",
        "   breakdown showing user preferences across different mobile brands.\n",
        "\n",
        "4. **Insurance Data**: Relatively newer data stream showing insurance transaction patterns, indicating PhonePe's\n",
        "   expansion into fintech services.\n",
        "\n",
        "5. **Data Quality**: The datasets appear clean with minimal missing values, well-structured JSON format, and\n",
        "   consistent temporal organization.\n",
        "\n",
        "6. **Temporal Coverage**: Quarterly data spanning 6+ years provides excellent opportunity for trend analysis\n",
        "   and seasonal pattern identification.\n",
        "\n",
        "7. **Business Relevance**: The data directly supports all five selected business case studies covering\n",
        "   transaction dynamics, device preferences, insurance penetration, market expansion, and user engagement."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(\"Transaction Dataset Columns:\")\n",
        "print(transaction_df.columns.tolist())\n",
        "print(\"\\nUser Dataset Columns:\")\n",
        "print(user_df.columns.tolist())\n",
        "print(\"\\nInsurance Dataset Columns:\")\n",
        "print(insurance_df.columns.tolist())"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "print(\"Transaction Dataset Statistics:\")\n",
        "print(transaction_df.describe())\n",
        "print(\"\\nUser Dataset Statistics:\")\n",
        "print(user_df.describe())\n",
        "print(\"\\nInsurance Dataset Statistics:\")\n",
        "print(insurance_df.describe())"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transaction Dataset Variables:**\n",
        "- year: Year of the transaction (2018-2024)\n",
        "- quarter: Quarter of the year (1-4)\n",
        "- category: Payment category (Recharge & bill payments, Peer-to-peer payments, etc.)\n",
        "- count: Number of transactions in the category\n",
        "- amount: Total transaction value in INR\n",
        "\n",
        "**User Dataset Variables:**\n",
        "- year: Year of user data (2018-2024)\n",
        "- quarter: Quarter of the year (1-4)\n",
        "- type: Data type (aggregated or device-specific)\n",
        "- brand: Device brand (Xiaomi, Samsung, etc.) or 'Total' for aggregated\n",
        "- registered_users: Number of registered users\n",
        "- app_opens: Number of app opens (available for aggregated data)\n",
        "- percentage: Percentage share of the device brand\n",
        "\n",
        "**Insurance Dataset Variables:**\n",
        "- year: Year of insurance data (2020-2024)\n",
        "- quarter: Quarter of the year (1-4)\n",
        "- category: Insurance category (typically 'Insurance')\n",
        "- count: Number of insurance transactions\n",
        "- amount: Total insurance transaction value in INR\n",
        "\n",
        "These variables enable comprehensive analysis of payment patterns, user behavior, and insurance adoption across\n",
        "temporal and categorical dimensions."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "print(\"Transaction Dataset Unique Values:\")\n",
        "for col in transaction_df.columns:\n",
        "    print(f\"{col}: {transaction_df[col].nunique()} unique values\")\n",
        "    if transaction_df[col].nunique() < 20:\n",
        "        print(f\"  Values: {sorted(transaction_df[col].unique())}\")\n",
        "\n",
        "print(\"\\nUser Dataset Unique Values:\")\n",
        "for col in user_df.columns:\n",
        "    print(f\"{col}: {user_df[col].nunique()} unique values\")\n",
        "    if user_df[col].nunique() < 20:\n",
        "        print(f\"  Values: {sorted(user_df[col].unique()) if user_df[col].dtype == 'object' else 'Numeric values'}\")\n",
        "\n",
        "print(\"\\nInsurance Dataset Unique Values:\")\n",
        "for col in insurance_df.columns:\n",
        "    print(f\"{col}: {insurance_df[col].nunique()} unique values\")\n",
        "    if insurance_df[col].nunique() < 20:\n",
        "        print(f\"  Values: {sorted(insurance_df[col].unique())}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create date columns for better temporal analysis\n",
        "transaction_df['date'] = pd.to_datetime(transaction_df['year'].astype(str) + '-' +\n",
        "                                       (transaction_df['quarter'] * 3).astype(str) + '-01')\n",
        "user_df['date'] = pd.to_datetime(user_df['year'].astype(str) + '-' +\n",
        "                                (user_df['quarter'] * 3).astype(str) + '-01')\n",
        "insurance_df['date'] = pd.to_datetime(insurance_df['year'].astype(str) + '-' +\n",
        "                                     (insurance_df['quarter'] * 3).astype(str) + '-01')\n",
        "\n",
        "# Create derived metrics\n",
        "transaction_df['avg_transaction_value'] = transaction_df['amount'] / transaction_df['count']\n",
        "transaction_df['amount_millions'] = transaction_df['amount'] / 1e6\n",
        "transaction_df['count_thousands'] = transaction_df['count'] / 1e3\n",
        "\n",
        "# Filter aggregated user data for time series analysis\n",
        "user_agg_df = user_df[user_df['type'] == 'aggregated'].copy()\n",
        "user_device_df = user_df[user_df['type'] == 'device'].copy()\n",
        "\n",
        "# Calculate engagement rate for aggregated users\n",
        "user_agg_df['engagement_rate'] = user_agg_df['app_opens'] / user_agg_df['registered_users']\n",
        "\n",
        "# Create insurance penetration metrics\n",
        "insurance_df['avg_insurance_value'] = insurance_df['amount'] / insurance_df['count']\n",
        "insurance_df['amount_millions'] = insurance_df['amount'] / 1e6\n",
        "\n",
        "# Remove any potential outliers using IQR method\n",
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "# Apply outlier removal to transaction amounts\n",
        "transaction_df_clean = remove_outliers(transaction_df, 'avg_transaction_value')\n",
        "\n",
        "print(f\"Original transaction records: {len(transaction_df)}\")\n",
        "print(f\"After outlier removal: {len(transaction_df_clean)}\")"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Temporal Enhancement**: Created proper date columns from year/quarter data for time series analysis\n",
        "2. **Derived Metrics**:\n",
        "   - Average transaction value per transaction\n",
        "   - Scaled amounts to millions/thousands for better readability\n",
        "   - User engagement rate (app opens per registered user)\n",
        "   - Insurance penetration metrics\n",
        "\n",
        "3. **Data Segmentation**: Separated aggregated user data from device-specific data for focused analysis\n",
        "4. **Outlier Treatment**: Applied IQR method to remove extreme values in transaction amounts\n",
        "5. **Data Type Optimization**: Ensured proper data types for numerical and categorical variables\n",
        "\n",
        "**Key Insights Found:**\n",
        "- Transaction data shows consistent quarterly patterns across payment categories\n",
        "- User engagement rates vary significantly across time periods\n",
        "- Insurance data starts from 2020, indicating service launch timing\n",
        "- Device-wise user distribution shows clear brand preferences\n",
        "- Average transaction values differ substantially across payment categories\n",
        "- Data quality is high with minimal missing values requiring imputation\n",
        "\n",
        "These manipulations prepare the dataset for comprehensive exploratory analysis and statistical modeling."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1: Transaction Volume Trends Over Time\n",
        "plt.figure(figsize=(12, 6))\n",
        "time_series = transaction_df.groupby(['year', 'quarter'])['count'].sum().reset_index()\n",
        "time_series['period'] = time_series['year'].astype(str) + '-Q' + time_series['quarter'].astype(str)\n",
        "plt.plot(time_series['period'], time_series['count'], marker='o', linewidth=2, markersize=6)\n",
        "plt.title('PhonePe Transaction Volume Trends (2018-2024)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Time Period', fontsize=12)\n",
        "plt.ylabel('Total Transaction Count', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a line chart to visualize transaction volume trends because:\n",
        "- Line charts are ideal for showing temporal patterns and trends over time\n",
        "- They clearly display growth rates, seasonal patterns, and inflection points\n",
        "- The continuous nature of time series data is best represented with connected points\n",
        "- Easy to identify periods of rapid growth, plateau, or decline"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from the transaction volume trend chart:\n",
        "- Consistent growth trajectory from 2018 to 2024 with some seasonal variations\n",
        "- Significant acceleration in growth during 2020-2021 (likely due to COVID-19 digital adoption)\n",
        "- Some quarterly seasonality with Q4 typically showing higher transaction volumes\n",
        "- Recent periods show stabilization indicating market maturity"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights drive positive business impact by:\n",
        "- **Capacity Planning**: Anticipating peak periods for infrastructure scaling\n",
        "- **Marketing Budget Allocation**: Timing campaigns during high-growth periods\n",
        "- **Product Development**: Understanding user behavior patterns for feature development\n",
        "- **Financial Forecasting**: Predicting revenue based on transaction trends\n",
        "- **Strategic Planning**: Identifying growth opportunities and market saturation points"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2: Payment Category Distribution\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "category_values = transaction_df.groupby('category')['amount'].sum()\n",
        "plt.pie(category_values.values, labels=category_values.index)\n",
        "plt.title('Payment Category Distribution by Transaction Value')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected a pie chart for payment category distribution because:\n",
        "- Pie charts effectively show proportional relationships and market share\n",
        "- They provide immediate visual understanding of category dominance\n",
        "- Perfect for displaying categorical data with percentage breakdowns\n",
        "- Helps identify which payment categories drive the most value"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from payment category distribution:\n",
        "- Peer-to-peer payments dominate the transaction value landscape\n",
        "- Recharge & bill payments represent a significant portion of total value\n",
        "- Merchant payments show substantial adoption\n",
        "- Financial services and other categories are growing but remain smaller segments\n",
        "- Category concentration indicates opportunities for diversification"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights enable positive business impact through:\n",
        "- **Product Strategy**: Focus development resources on high-value categories\n",
        "- **Revenue Optimization**: Implement targeted pricing strategies for dominant categories\n",
        "- **Partnership Opportunities**: Identify categories needing strategic partnerships\n",
        "- **User Experience**: Optimize UI/UX for most-used payment categories\n",
        "- **Market Expansion**: Develop strategies to grow underrepresented categories"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3: Device Brand Market Share\n",
        "plt.figure(figsize=(12, 6))\n",
        "device_share = user_device_df.groupby('brand')['registered_users'].sum().sort_values(ascending=False).head(10)\n",
        "sns.barplot(x=device_share.values, y=device_share.index, palette='viridis')\n",
        "plt.title('Top 10 Device Brands by Registered Users', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Number of Registered Users', fontsize=12)\n",
        "plt.ylabel('Device Brand', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a horizontal bar chart for device brand analysis because:\n",
        "- Bar charts are excellent for comparing categorical data\n",
        "- Horizontal orientation accommodates longer brand names\n",
        "- Easy to rank brands by user count\n",
        "- Clear visual hierarchy showing market dominance"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from device brand distribution:\n",
        "- Xiaomi leads in user registrations, indicating strong market presence\n",
        "- Samsung and OnePlus show significant user bases\n",
        "- Clear tier structure with top 3 brands dominating\n",
        "- 'Others' category represents substantial fragmentation\n",
        "- Brand preferences align with India's smartphone market trends"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights drive business impact through:\n",
        "- **App Optimization**: Prioritize performance for top device brands\n",
        "- **Partnership Strategy**: Focus on brands with highest user concentration\n",
        "- **Marketing Targeting**: Tailor campaigns to specific device ecosystems\n",
        "- **Technical Support**: Optimize customer service for popular devices\n",
        "- **Product Development**: Ensure compatibility with market-leading brands"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4: User Engagement Rate Trends\n",
        "plt.figure(figsize=(12, 6))\n",
        "engagement_trends = user_agg_df.groupby(['year', 'quarter'])['engagement_rate'].mean().reset_index()\n",
        "engagement_trends['period'] = engagement_trends['year'].astype(str) + '-Q' + engagement_trends['quarter'].astype(str)\n",
        "plt.plot(engagement_trends['period'], engagement_trends['engagement_rate'], marker='s', linewidth=2, markersize=6, color='red')\n",
        "plt.title('User Engagement Rate Trends (App Opens per Registered User)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Time Period', fontsize=12)\n",
        "plt.ylabel('Engagement Rate', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected a line chart for engagement rate trends because:\n",
        "- Time series data requires temporal visualization\n",
        "- Line charts show progression and patterns over time\n",
        "- Engagement rates are continuous metrics best shown with connected points\n",
        "- Easy to identify engagement improvement or decline periods"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from user engagement trends:\n",
        "- Engagement rates show cyclical patterns with quarterly variations\n",
        "- Overall engagement has improved over time, indicating product stickiness\n",
        "- Certain periods show engagement spikes (possibly during promotional campaigns)\n",
        "- Recent trends suggest stabilization at higher engagement levels\n",
        "- Strong correlation between engagement and business growth periods"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights create positive business impact by:\n",
        "- **Product Development**: Focus on features that drive sustained engagement\n",
        "- **Marketing Strategy**: Time campaigns during naturally high-engagement periods\n",
        "- **User Retention**: Implement strategies to maintain engagement levels\n",
        "- **Customer Lifecycle**: Understand user behavior patterns for better targeting\n",
        "- **Revenue Optimization**: Higher engagement correlates with increased transaction frequency"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5: Insurance Adoption Trends\n",
        "plt.figure(figsize=(12, 6))\n",
        "insurance_trends = insurance_df.groupby(['year', 'quarter'])['count'].sum().reset_index()\n",
        "insurance_trends['period'] = insurance_trends['year'].astype(str) + '-Q' + insurance_trends['quarter'].astype(str)\n",
        "plt.bar(insurance_trends['period'], insurance_trends['count'], color='orange', alpha=0.7)\n",
        "plt.title('Insurance Transaction Growth Trends', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Time Period', fontsize=12)\n",
        "plt.ylabel('Insurance Transaction Count', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a bar chart for insurance adoption trends because:\n",
        "- Bar charts effectively show discrete quarterly data\n",
        "- Visual comparison between time periods is clear\n",
        "- Growth patterns are immediately apparent\n",
        "- Seasonal variations are easy to identify"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from insurance adoption trends:\n",
        "- Insurance services launched around 2020, showing PhonePe's diversification\n",
        "- Steady growth in insurance transaction volume over time\n",
        "- Quarterly variations suggest seasonal insurance buying patterns\n",
        "- Recent periods show accelerated adoption\n",
        "- Insurance represents a growing revenue stream for PhonePe"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights drive positive business impact through:\n",
        "- **Product Strategy**: Expand insurance offerings based on adoption trends\n",
        "- **Marketing Timing**: Align insurance campaigns with seasonal patterns\n",
        "- **Partnership Development**: Strengthen relationships with insurance providers\n",
        "- **Cross-selling Opportunities**: Leverage transaction data for targeted insurance offers\n",
        "- **Revenue Diversification**: Reduce dependence on traditional payment revenues"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6: Average Transaction Value by Category\n",
        "plt.figure(figsize=(12, 8))\n",
        "avg_transaction_by_category = transaction_df.groupby('category')['avg_transaction_value'].mean().sort_values(ascending=True)\n",
        "plt.barh(avg_transaction_by_category.index, avg_transaction_by_category.values, color='skyblue')\n",
        "plt.title('Average Transaction Value by Payment Category', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Average Transaction Value (INR)', fontsize=12)\n",
        "plt.ylabel('Payment Category', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected a horizontal bar chart for average transaction values because:\n",
        "- Horizontal bars accommodate longer category names\n",
        "- Easy comparison of average values across categories\n",
        "- Clear ranking of categories by transaction value\n",
        "- Immediate identification of high-value vs. low-value categories"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from average transaction values:\n",
        "- Financial services show highest average transaction values\n",
        "- Peer-to-peer payments have moderate average values\n",
        "- Recharge & bill payments typically involve smaller amounts\n",
        "- Merchant payments show varied transaction sizes\n",
        "- Category behavior aligns with expected use cases"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights enable positive business impact by:\n",
        "- **Pricing Strategy**: Implement category-specific fee structures\n",
        "- **Risk Management**: Adjust fraud detection based on transaction patterns\n",
        "- **Product Development**: Design features suitable for different value ranges\n",
        "- **Customer Segmentation**: Target users based on transaction behavior\n",
        "- **Revenue Optimization**: Focus on high-value categories for growth"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7: Quarterly Growth Rate Analysis\n",
        "plt.figure(figsize=(12, 6))\n",
        "quarterly_growth = transaction_df.groupby(['year', 'quarter'])['count'].sum().reset_index()\n",
        "quarterly_growth['growth_rate'] = quarterly_growth['count'].pct_change() * 100\n",
        "quarterly_growth['period'] = quarterly_growth['year'].astype(str) + '-Q' + quarterly_growth['quarter'].astype(str)\n",
        "quarterly_growth = quarterly_growth.dropna()\n",
        "\n",
        "plt.plot(quarterly_growth['period'], quarterly_growth['growth_rate'], marker='o', linewidth=2, markersize=6, color='green')\n",
        "plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
        "plt.title('Quarterly Growth Rate in Transaction Volume', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Time Period', fontsize=12)\n",
        "plt.ylabel('Growth Rate (%)', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a line chart with zero reference for growth rate analysis because:\n",
        "- Growth rates are continuous metrics best shown with connected points\n",
        "- Zero line helps identify positive vs. negative growth periods\n",
        "- Temporal patterns in growth are clearly visible\n",
        "- Easy to spot acceleration or deceleration in business growth"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from quarterly growth rate analysis:\n",
        "- Growth rates show volatility with both positive and negative quarters\n",
        "- Certain periods show exceptional growth (likely during digital adoption surge)\n",
        "- Recent quarters show stabilization indicating market maturity\n",
        "- Seasonal patterns in growth rates are evident\n",
        "- Overall trend suggests sustainable long-term growth"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights create positive business impact through:\n",
        "- **Strategic Planning**: Anticipate growth cycles for resource allocation\n",
        "- **Investment Decisions**: Time expansion based on growth patterns\n",
        "- **Performance Monitoring**: Set realistic growth targets based on historical data\n",
        "- **Risk Management**: Prepare for potential slowdown periods\n",
        "- **Market Positioning**: Understand competitive landscape during different growth phases"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8: Insurance Penetration Analysis\n",
        "plt.figure(figsize=(12, 8))\n",
        "# Calculate insurance penetration as percentage of total transactions\n",
        "total_transactions = transaction_df.groupby(['year', 'quarter'])['count'].sum().reset_index()\n",
        "insurance_transactions = insurance_df.groupby(['year', 'quarter'])['count'].sum().reset_index()\n",
        "penetration_data = total_transactions.merge(insurance_transactions, on=['year', 'quarter'], suffixes=('_total', '_insurance'))\n",
        "penetration_data['penetration_rate'] = (penetration_data['count_insurance'] / penetration_data['count_total']) * 100\n",
        "penetration_data['period'] = penetration_data['year'].astype(str) + '-Q' + penetration_data['quarter'].astype(str)\n",
        "\n",
        "plt.plot(penetration_data['period'], penetration_data['penetration_rate'], marker='o', linewidth=2, markersize=6, color='purple')\n",
        "plt.title('Insurance Penetration Rate Over Time', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Time Period', fontsize=12)\n",
        "plt.ylabel('Insurance Penetration Rate (%)', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a line chart for insurance penetration analysis because:\n",
        "- Penetration rates are continuous metrics best shown over time\n",
        "- Line charts clearly show adoption trends and growth patterns\n",
        "- Easy to identify periods of rapid adoption or stagnation\n",
        "- Temporal progression is crucial for understanding market development"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from insurance penetration analysis:\n",
        "- Insurance penetration has grown since its introduction\n",
        "- Adoption curve shows typical new product launch patterns\n",
        "- Recent periods indicate accelerating adoption\n",
        "- Penetration rates suggest significant room for growth\n",
        "- Market education and awareness campaigns appear to be working"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights enable positive business impact through:\n",
        "- **Product Strategy**: Accelerate insurance product development\n",
        "- **Marketing Investment**: Increase budget allocation for insurance promotion\n",
        "- **Partnership Expansion**: Develop relationships with more insurance providers\n",
        "- **Customer Education**: Implement targeted awareness campaigns\n",
        "- **Revenue Diversification**: Reduce dependence on traditional payment revenues"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13: Payment Category Performance Dashboard\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Subplot 1: Category Volume Trends\n",
        "plt.subplot(2, 2, 1)\n",
        "category_trends = transaction_df.groupby(['category', 'year'])['count'].sum().unstack()\n",
        "category_trends.plot(kind='bar', stacked=True, ax=plt.gca())\n",
        "plt.title('Transaction Volume by Category Over Years')\n",
        "plt.xlabel('Payment Category')\n",
        "plt.ylabel('Transaction Count')\n",
        "plt.legend(title='Year', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a multi-panel dashboard for category performance because:\n",
        "- Dashboard approach provides comprehensive category analysis\n",
        "- Multiple visualizations reveal different performance dimensions\n",
        "- Enables comparison across volume, value, growth, and efficiency metrics\n",
        "- Stakeholders can quickly assess category performance holistically"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from payment category performance dashboard:\n",
        "- Different categories show distinct performance patterns\n",
        "- Some categories excel in volume while others in value\n",
        "- Growth rates vary significantly across categories\n",
        "- Average transaction values indicate different use cases\n",
        "- Category portfolio shows diversified business model"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights enable positive business impact through:\n",
        "- **Strategic Planning**: Allocate resources based on category performance\n",
        "- **Product Development**: Focus on high-growth, high-value categories\n",
        "- **Marketing Strategy**: Tailor campaigns to category-specific patterns\n",
        "- **Revenue Optimization**: Maximize returns from best-performing categories\n",
        "- **Risk Management**: Diversify across categories to reduce concentration risk"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(12, 8))\n",
        "numeric_cols = ['year', 'quarter', 'count', 'amount', 'avg_transaction_value']\n",
        "correlation_matrix = transaction_df[numeric_cols].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True, fmt='.3f')\n",
        "plt.title('Transaction Data Correlation Matrix', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected a correlation heatmap because:\n",
        "- Heatmaps effectively visualize correlation strength between multiple variables\n",
        "- Color coding makes correlation patterns immediately apparent\n",
        "- Essential for understanding multicollinearity before modeling\n",
        "- Helps identify the most influential variables for business decisions"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from the correlation heatmap:\n",
        "- Strong positive correlation between transaction count and amount\n",
        "- Temporal variables show varying correlations with transaction metrics\n",
        "- Average transaction value shows different patterns than total metrics\n",
        "- Year shows positive correlation with transaction growth\n",
        "- Quarter shows seasonal correlation patterns"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "plt.figure(figsize=(12, 10))\n",
        "# Sample a number of rows up to the total number of rows in the dataframe\n",
        "sample_size = min(1000, len(transaction_df))\n",
        "pair_plot_data = transaction_df[['count', 'amount', 'avg_transaction_value']].sample(n=sample_size)\n",
        "sns.pairplot(pair_plot_data, diag_kind='hist', plot_kws={'alpha': 0.6})\n",
        "plt.suptitle('Transaction Data Pair Plot Analysis', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a pair plot for multivariate analysis because:\n",
        "- Pair plots show relationships between all variable combinations\n",
        "- Diagonal histograms reveal individual variable distributions\n",
        "- Scatter plots in the matrix show bivariate relationships\n",
        "- Comprehensive view of data structure before modeling"
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key insights from the pair plot analysis:\n",
        "- Transaction count and amount show strong positive relationship\n",
        "- Average transaction value has different distribution patterns\n",
        "- Some variables show non-linear relationships\n",
        "- Data distributions vary across different metrics\n",
        "- Outliers are present in certain variable combinations"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the exploratory data analysis, I have identified three key hypothetical statements for statistical testing:\n",
        "\n",
        "1. **Transaction Volume Hypothesis**: There is a significant difference in transaction volumes between different payment categories, with peer-to-peer payments showing significantly higher volumes than other categories.\n",
        "\n",
        "2. **Seasonal Effect Hypothesis**: There is a significant seasonal effect on transaction values, with Q4 (October-December) showing significantly higher transaction values compared to other quarters.\n",
        "\n",
        "3. **User Engagement Hypothesis**: There is a significant positive correlation between the number of registered users and app opens, indicating that user growth directly translates to increased engagement.\n",
        "\n",
        "These hypotheses address core business questions about payment patterns, seasonality, and user behavior that can inform strategic decisions."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H₀)**: There is no significant difference in mean transaction counts between different payment categories.\n",
        "\n",
        "**Alternative Hypothesis (H₁)**: There is a significant difference in mean transaction counts between different payment categories.\n",
        "\n",
        "This hypothesis tests whether payment categories perform equally or if some categories significantly outperform others in terms of transaction volume."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Prepare data for ANOVA\n",
        "categories = transaction_df['category'].unique()\n",
        "category_groups = []\n",
        "for category in categories:\n",
        "    category_data = transaction_df[transaction_df['category'] == category]['count']\n",
        "    category_groups.append(category_data)\n",
        "\n",
        "# Perform ANOVA\n",
        "f_statistic, p_value = f_oneway(*category_groups)\n",
        "\n",
        "print(f\"One-Way ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Alpha level: 0.05\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Result: Reject null hypothesis - There is a significant difference between categories\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject null hypothesis - No significant difference between categories\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed a One-Way ANOVA (Analysis of Variance) test to obtain the P-value. ANOVA is used to compare means across multiple groups (payment categories) simultaneously."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose One-Way ANOVA because:\n",
        "- It's designed to test differences between multiple groups (payment categories)\n",
        "- Compares means across all categories simultaneously\n",
        "- More appropriate than multiple t-tests (avoids Type I error inflation)\n",
        "- Suitable for continuous dependent variable (transaction count) and categorical independent variable (payment category)\n",
        "- Provides overall test of whether any categories differ significantly"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H₀)**: There is no significant difference in mean transaction values between different quarters (no seasonal effect).\n",
        "\n",
        "**Alternative Hypothesis (H₁)**: There is a significant difference in mean transaction values between different quarters (seasonal effect exists).\n",
        "\n",
        "This hypothesis tests whether transaction values vary significantly across quarters, indicating seasonal patterns in payment behavior."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "quarters = transaction_df['quarter'].unique()\n",
        "quarter_groups = []\n",
        "for quarter in quarters:\n",
        "    quarter_data = transaction_df[transaction_df['quarter'] == quarter]['amount']\n",
        "    quarter_groups.append(quarter_data)\n",
        "\n",
        "# Perform ANOVA\n",
        "f_statistic_q, p_value_q = f_oneway(*quarter_groups)\n",
        "\n",
        "print(f\"Quarterly ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_statistic_q:.4f}\")\n",
        "print(f\"P-value: {p_value_q:.4f}\")\n",
        "print(f\"Alpha level: 0.05\")\n",
        "\n",
        "if p_value_q < 0.05:\n",
        "    print(\"Result: Reject null hypothesis - There is a significant seasonal effect\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject null hypothesis - No significant seasonal effect\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed a One-Way ANOVA test to analyze quarterly differences in transaction values."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose One-Way ANOVA for quarterly analysis because:\n",
        "- It compares means across four quarters simultaneously\n",
        "- Appropriate for testing seasonal effects with categorical time periods\n",
        "- Avoids multiple comparison problems\n",
        "- Suitable for continuous dependent variable (transaction amount) and categorical independent variable (quarter)\n",
        "- Provides comprehensive test of seasonal variations"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Check for missing values in all datasets\n",
        "print(\"Missing Values Analysis:\")\n",
        "print(f\"Transaction data missing values: {transaction_df.isnull().sum().sum()}\")\n",
        "print(f\"User data missing values: {user_df.isnull().sum().sum()}\")\n",
        "print(f\"Insurance data missing values: {insurance_df.isnull().sum().sum()}\")\n",
        "\n",
        "# Handle missing values if any exist\n",
        "if transaction_df.isnull().sum().sum() > 0:\n",
        "    transaction_df = transaction_df.fillna(transaction_df.median())\n",
        "    print(\"Missing values in transaction data filled with median\")\n",
        "else:\n",
        "    print(\"No missing values found in transaction data\")\n",
        "\n",
        "if user_df.isnull().sum().sum() > 0:\n",
        "    user_df = user_df.fillna(user_df.median())\n",
        "    print(\"Missing values in user data filled with median\")\n",
        "else:\n",
        "    print(\"No missing values found in user data\")\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing Value Imputation Techniques Used:**\n",
        "\n",
        "1. **Median Imputation**: For numerical variables, I used median imputation because:\n",
        "   - Median is robust to outliers compared to mean\n",
        "   - Appropriate for skewed distributions common in financial data\n",
        "   - Maintains the central tendency of the data\n",
        "   - Simple and interpretable method\n",
        "\n",
        "2. **No Imputation Required**: The PhonePe Pulse dataset appears to be well-maintained with minimal missing values, which is typical for production-grade datasets.\n",
        "\n",
        "**Why These Techniques:**\n",
        "- Median imputation preserves the distribution shape\n",
        "- Avoids introducing bias that mean imputation might cause with skewed data\n",
        "- Maintains sample size for analysis\n",
        "- Suitable for the business context where extreme values are common"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Identify and handle outliers using IQR method(Interquatile Range)\n",
        "def detect_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "    return outliers, lower_bound, upper_bound\n",
        "\n",
        "# Detect outliers in transaction amounts\n",
        "outliers_amount, lower_amt, upper_amt = detect_outliers(transaction_df, 'amount')\n",
        "print(f\"Outliers in transaction amount: {len(outliers_amount)} records\")\n",
        "\n",
        "# Detect outliers in transaction counts\n",
        "outliers_count, lower_cnt, upper_cnt = detect_outliers(transaction_df, 'count')\n",
        "print(f\"Outliers in transaction count: {len(outliers_count)} records\")\n",
        "\n",
        "# Apply winsorization instead of removal to preserve data\n",
        "from scipy.stats import mstats\n",
        "transaction_df['amount_winsorized'] = mstats.winsorize(transaction_df['amount'], limits=[0.01, 0.01])\n",
        "transaction_df['count_winsorized'] = mstats.winsorize(transaction_df['count'], limits=[0.01, 0.01])\n",
        "\n",
        "print(\"Outliers handled using winsorization (1st and 99th percentiles)\")"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outlier Treatment Techniques Used:**\n",
        "\n",
        "1. **IQR Method for Detection**: Used Interquartile Range method to identify outliers because:\n",
        "   - Non-parametric approach suitable for skewed distributions\n",
        "   - Robust to extreme values\n",
        "   - Industry standard for financial data analysis\n",
        "   - Clear mathematical definition of outliers\n",
        "\n",
        "2. **Winsorization for Treatment**: Applied winsorization (1st and 99th percentiles) because:\n",
        "   - Preserves data points while reducing extreme impact\n",
        "   - Maintains sample size for analysis\n",
        "   - More conservative than outlier removal\n",
        "   - Appropriate for business data where extreme values may be legitimate\n",
        "\n",
        "**Why These Techniques:**\n",
        "- Removal would lose valuable information about extreme transactions\n",
        "- Winsorization maintains the rank order of data\n",
        "- Suitable for machine learning model training\n",
        "- Balances outlier impact reduction with information preservation"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables\n",
        "le_category = LabelEncoder()\n",
        "transaction_df['category_encoded'] = le_category.fit_transform(transaction_df['category'])\n",
        "\n",
        "le_brand = LabelEncoder()\n",
        "user_df['brand_encoded'] = user_df['brand'].map(lambda x: le_brand.fit_transform([x])[0] if pd.notnull(x) else 0)\n",
        "\n",
        "# Create dummy variables for categorical columns\n",
        "transaction_dummies = pd.get_dummies(transaction_df['category'], prefix='category')\n",
        "transaction_df = pd.concat([transaction_df, transaction_dummies], axis=1)\n",
        "\n",
        "user_dummies = pd.get_dummies(user_df['brand'], prefix='brand')\n",
        "user_df = pd.concat([user_df, user_dummies], axis=1)\n",
        "\n",
        "print(\"Categorical encoding completed:\")\n",
        "print(f\"Transaction categories encoded: {transaction_df['category'].nunique()}\")\n",
        "print(f\"User device brands encoded: {user_df['brand'].nunique()}\")"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical Encoding Techniques Used:**\n",
        "\n",
        "1. **Label Encoding**: Applied to ordinal or nominal categories with natural ordering:\n",
        "   - Converts categories to numerical values\n",
        "   - Memory efficient for high-cardinality features\n",
        "   - Suitable for tree-based models\n",
        "\n",
        "2. **One-Hot Encoding (Dummy Variables)**: Applied to nominal categories:\n",
        "   - Creates binary columns for each category\n",
        "   - Prevents ordinal assumptions in categories\n",
        "   - Suitable for linear models and neural networks\n",
        "\n",
        "**Why These Techniques:**\n",
        "- **Label Encoding**: Appropriate for payment categories where some natural ordering exists\n",
        "- **One-Hot Encoding**: Prevents false ordinal relationships between device brands\n",
        "- **Combination Approach**: Provides flexibility for different model types\n",
        "- **Business Context**: Maintains interpretability for stakeholder understanding"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create additional features for better analysis\n",
        "transaction_df['year_quarter'] = transaction_df['year'].astype(str) + '_Q' + transaction_df['quarter'].astype(str)\n",
        "transaction_df['log_amount'] = np.log1p(transaction_df['amount'])\n",
        "transaction_df['log_count'] = np.log1p(transaction_df['count'])\n",
        "transaction_df['amount_per_count'] = transaction_df['amount'] / transaction_df['count']\n",
        "\n",
        "# Create time-based features\n",
        "transaction_df['time_trend'] = (transaction_df['year'] - transaction_df['year'].min()) * 4 + transaction_df['quarter']\n",
        "\n",
        "# Create interaction features\n",
        "transaction_df['year_category_interaction'] = transaction_df['year'] * transaction_df['category_encoded']\n",
        "\n",
        "# User engagement features\n",
        "user_agg_df['engagement_score'] = user_agg_df['app_opens'] / user_agg_df['registered_users']\n",
        "user_agg_df['log_users'] = np.log1p(user_agg_df['registered_users'])\n",
        "user_agg_df['log_opens'] = np.log1p(user_agg_df['app_opens'])\n",
        "\n",
        "print(\"Feature manipulation completed:\")\n",
        "print(f\"New transaction features: {len([col for col in transaction_df.columns if col not in ['year', 'quarter', 'category', 'count', 'amount']])}\")\n",
        "print(f\"New user features: {len([col for col in user_agg_df.columns if col not in ['year', 'quarter', 'registered_users', 'app_opens']])}\")"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select features based on correlation and business importance\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Prepare features for selection\n",
        "feature_columns = ['year', 'quarter', 'category_encoded', 'log_amount', 'log_count', 'time_trend']\n",
        "X_features = transaction_df[feature_columns]\n",
        "y_target = transaction_df['amount']\n",
        "\n",
        "# Apply SelectKBest\n",
        "selector = SelectKBest(score_func=f_regression, k=5)\n",
        "X_selected = selector.fit_transform(X_features, y_target)\n",
        "selected_features = [feature_columns[i] for i in selector.get_support(indices=True)]\n",
        "\n",
        "print(\"Feature selection completed:\")\n",
        "print(f\"Selected features: {selected_features}\")\n",
        "print(f\"Feature scores: {selector.scores_}\")\n"
      ],
      "metadata": {
        "id": "1ADHqjdJWyy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **SelectKBest with F-Regression**: Used to select top features based on statistical significance:\n",
        "   - Measures linear relationship between features and target\n",
        "   - Removes irrelevant features that don't contribute to prediction\n",
        "   - Computationally efficient for large datasets\n",
        "\n",
        "2. **Correlation-Based Selection**: Analyzed correlation matrix to identify highly correlated features:\n",
        "   - Prevents multicollinearity issues\n",
        "   - Reduces model complexity\n",
        "   - Maintains interpretability\n",
        "\n",
        "3. **Business Knowledge-Based Selection**: Included features with known business importance:\n",
        "   - Ensures model includes relevant business drivers\n",
        "   - Maintains model interpretability for stakeholders\n",
        "   - Incorporates domain expertise\n",
        "\n",
        "\n",
        "**Why These Methods:**\n",
        "- **Statistical Significance**: Ensures selected features have predictive power\n",
        "- **Multicollinearity Prevention**: Improves model stability and interpretation\n",
        "- **Business Relevance**: Maintains practical applicability of insights\n",
        "- **Model Performance**: Balances complexity with predictive accuracy"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important Features Identified:**\n",
        "\n",
        "1. **Time Trend**: Strong predictor of transaction growth patterns\n",
        "   - Captures underlying business growth\n",
        "   - Essential for forecasting future performance\n",
        "\n",
        "2. **Log Amount**: Normalized transaction values reduce skewness\n",
        "   - Improves model performance with extreme values\n",
        "   - Maintains proportional relationships\n",
        "\n",
        "3. **Category Encoded**: Payment category significantly impacts transaction patterns\n",
        "   - Different categories have distinct behaviors\n",
        "   - Critical for category-specific strategies\n",
        "\n",
        "4. **Year and Quarter**: Temporal features capture seasonality and trends\n",
        "   - Essential for time series analysis\n",
        "   - Captures business cycles and seasonal patterns\n",
        "\n",
        "5. **Log Count**: Normalized transaction counts\n",
        "   - Reduces impact of outliers\n",
        "   - Maintains relationship with transaction volume\n",
        "\n",
        "**Why These Features Are Important:**\n",
        "- **Predictive Power**: High correlation with target variables\n",
        "- **Business Relevance**: Directly relate to strategic decisions\n",
        "- **Statistical Significance**: Pass significance tests for inclusion\n",
        "- **Interpretability**: Clear business meaning for stakeholder communication"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformations used:-**\n",
        "\n",
        "1. **Log Transformation**: Applied to amount and count variables\n",
        "   - Financial data often has exponential growth patterns and extreme values\n",
        "   \n",
        "2. **Normalization**: Applied to engagement rates and ratios\n",
        "   - Different scales between variables (users vs. app opens)\n",
        "   \n",
        "3. **Date Transformation**: Converted year/quarter to continuous time variables\n",
        "   - Time series analysis requires continuous temporal representation.\n",
        "\n",
        "**Transformations are necessary because**\n",
        "- **Scale Differences**: Variables have vastly different ranges\n",
        "- **Model Requirements**: ML algorithms perform better with normalized data\n",
        "- **Business Context**: Transformed data maintains business meaning while improving analysis"
      ],
      "metadata": {
        "id": "ElsZddKpXwh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "scaler = StandardScaler()\n",
        "transaction_df['amount_scaled'] = scaler.fit_transform(transaction_df[['amount']])\n",
        "transaction_df['count_scaled'] = scaler.fit_transform(transaction_df[['count']])\n",
        "\n",
        "print(\"Data transformation completed:\")\n",
        "print(f\"Scaling applied to amount and count variables\")\n",
        "print(f\"Log transformation applied to skewed variables\")\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "numerical_features = ['amount', 'count', 'avg_transaction_value', 'time_trend']\n",
        "scaler = StandardScaler()\n",
        "transaction_df[numerical_features] = scaler.fit_transform(transaction_df[numerical_features])\n",
        "\n",
        "print(\"Data scaling completed using StandardScaler\")\n",
        "print(f\"Scaled features: {numerical_features}\")"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Scaling Method Used: StandardScaler (normalization)\n",
        "Because :-  \n",
        "- **Zero Mean, Unit Variance**: Transforms data to have mean=0 and std=1\n",
        "- **Model Compatibility**: Works well with most machine learning algorithms"
      ],
      "metadata": {
        "id": "e28U8dsyYks-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why Dimensionality Reduction is NOT Heavily Needed:**\n",
        "1. **Moderate Feature Count**: Current feature count is manageable for most algorithms\n",
        "2. **Business Interpretability**: All features have clear business meaning\n",
        "3. **Feature Relevance**: Each feature contributes unique information\n",
        "4. **Model Performance**: Current dimensionality doesn't cause overfitting concerns"
      ],
      "metadata": {
        "id": "q2MV6S8SC5cT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data for machine learning\n",
        "X = transaction_df[selected_features]\n",
        "y = transaction_df['amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=transaction_df['category'])\n",
        "\n",
        "print(\"Data splitting completed:\")\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
        "print(f\"Training set percentage: {len(X_train)/(len(X_train)+len(X_test))*100:.1f}%\")\n",
        "print(f\"Test set percentage: {len(X_test)/(len(X_train)+len(X_test))*100:.1f}%\")"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Splitting Ratio Used: 80-20 (Train-Test)**\n",
        "\n",
        "**Why This Ratio Was Chosen:**\n",
        "- **Standard Practice**: 80-20 is widely accepted for datasets of this size\n",
        "- **Sufficient Training Data**: 80% provides adequate samples for model training\n",
        "- **Reliable Testing**: 20% gives statistically significant evaluation results\n",
        "- **Business Context**: Balances model learning with validation accuracy"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1: Random Forest Regressor"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest implementation\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
        "rf_rmse = np.sqrt(rf_mse)\n",
        "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
        "rf_r2 = r2_score(y_test, rf_predictions)\n",
        "\n",
        "print(\"Random Forest Model Performance:\")\n",
        "print(f\"RMSE: {rf_rmse:.2f}\")\n",
        "print(f\"MAE: {rf_mae:.2f}\")\n",
        "print(f\"R²: {rf_r2:.3f}\")\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "plt.subplot(2, 2, 4)\n",
        "metrics = ['RMSE', 'MAE', 'R²']\n",
        "values = [rf_rmse, rf_mae, rf_r2]\n",
        "plt.bar(metrics, values, color=['red', 'orange', 'green'])\n",
        "plt.title('Random Forest: Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "tuned_rf_predictions = best_rf_model.predict(X_test)\n",
        "tuned_rf_rmse = np.sqrt(mean_squared_error(y_test, tuned_rf_predictions))\n",
        "tuned_rf_mae = mean_absolute_error(y_test, tuned_rf_predictions)\n",
        "tuned_rf_r2 = r2_score(y_test, tuned_rf_predictions)\n",
        "\n",
        "print(\"Tuned Random Forest Performance:\")\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"RMSE: {tuned_rf_rmse:.2f}\")\n",
        "print(f\"MAE: {tuned_rf_mae:.2f}\")\n",
        "print(f\"R²: {tuned_rf_r2:.3f}\")\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Optimization Technique: GridSearchCV**\n",
        "\n",
        "**Why GridSearchCV Was Chosen:**\n",
        "- **Exhaustive Search**: Tests all parameter combinations systematically\n",
        "- **Cross-Validation**: Uses 5-fold CV for robust parameter selection\n",
        "- **Scikit-learn Integration**: Seamlessly works with sklearn models\n",
        "- **Reproducible Results**: Consistent parameter selection across runs\n",
        "\n",
        "**Benefits:**\n",
        "- **Automated Selection**: Removes manual parameter guessing\n",
        "- **Performance Optimization**: Finds optimal parameter combination\n",
        "- **Overfitting Prevention**: Cross-validation prevents overfitting to training data\n",
        "- **Computational Efficiency**: Parallel processing with n_jobs=-1"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Improvement Analysis:**\n",
        "\n",
        "**Before Tuning:**\n",
        "- RMSE: 0.17\n",
        "- MAE: 0.06\n",
        "- R²: 0.985\n",
        "\n",
        "**After Tuning:**\n",
        "- RMSE: 0.16\n",
        "- MAE: 0.06\n",
        "- R²: 0.986"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2: Gradient Boosting Regressor\n"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosting implementation\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "gb_predictions = gb_model.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
        "gb_rmse = np.sqrt(gb_mse)\n",
        "gb_mae = mean_absolute_error(y_test, gb_predictions)\n",
        "gb_r2 = r2_score(y_test, gb_predictions)\n",
        "\n",
        "print(\"Gradient Boosting Model Performance:\")\n",
        "print(f\"RMSE: {gb_rmse:.2f}\")\n",
        "print(f\"MAE: {gb_mae:.2f}\")\n",
        "print(f\"R²: {gb_r2:.3f}\")"
      ],
      "metadata": {
        "id": "cZn9ALldGY2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "plt.subplot(2, 2, 4)\n",
        "metrics = ['RMSE', 'MAE', 'R²']\n",
        "values = [gb_rmse, gb_mae, gb_r2]\n",
        "plt.bar(metrics, values, color=['red', 'orange', 'green'])\n",
        "plt.title('Gradient Boosting: Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for Gradient Boosting\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "gb_grid_search = GridSearchCV(\n",
        "    GradientBoostingRegressor(random_state=42),\n",
        "    gb_param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "gb_grid_search.fit(X_train, y_train)\n",
        "best_gb_model = gb_grid_search.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "tuned_gb_predictions = best_gb_model.predict(X_test)\n",
        "tuned_gb_rmse = np.sqrt(mean_squared_error(y_test, tuned_gb_predictions))\n",
        "tuned_gb_mae = mean_absolute_error(y_test, tuned_gb_predictions)\n",
        "tuned_gb_r2 = r2_score(y_test, tuned_gb_predictions)\n",
        "\n",
        "print(\"Tuned Gradient Boosting Performance:\")\n",
        "print(f\"Best parameters: {gb_grid_search.best_params_}\")\n",
        "print(f\"RMSE: {tuned_gb_rmse:.2f}\")\n",
        "print(f\"MAE: {tuned_gb_mae:.2f}\")\n",
        "print(f\"R²: {tuned_gb_r2:.3f}\")\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Optimization Technique: GridSearchCV**\n",
        "\n",
        "**Why GridSearchCV Was Chosen:**\n",
        "- **Comprehensive Search**: Tests all parameter combinations systematically\n",
        "- **Cross-Validation**: Uses 5-fold CV for robust parameter evaluation\n",
        "- **Consistent Methodology**: Same approach as Random Forest for fair comparison\n",
        "- **Parallel Processing**: Efficient computation with multiple cores\n",
        "\n",
        "**Benefits:**\n",
        "- **Optimal Performance**: Finds best parameter combination for this dataset\n",
        "- **Overfitting Prevention**: Cross-validation ensures generalization\n",
        "- **Systematic Approach**: Eliminates guesswork in parameter selection\n",
        "- **Reproducible Results**: Consistent parameter selection across runs"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Improvement Analysis:**\n",
        "\n",
        "**Before Tuning:**\n",
        "- RMSE: 0.11\n",
        "- MAE: 0.04\n",
        "- R²: 0.994\n",
        "\n",
        "**After Tuning:**\n",
        "- RMSE: 0.11\n",
        "- MAE: 0.04\n",
        "- R²: 0.994"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business Impact of Evaluation Metrics:**\n",
        "\n",
        "**RMSE (Root Mean Square Error):**\n",
        "- **Business Meaning**: Average prediction error in transaction amounts\n",
        "- **Impact**: Lower RMSE means more accurate financial forecasting\n",
        "- **Strategic Value**: Enables better budget planning and resource allocation\n",
        "- **Risk Management**: Reduces uncertainty in revenue projections\n",
        "\n",
        "**MAE (Mean Absolute Error):**\n",
        "- **Business Meaning**: Average absolute deviation from actual transaction values\n",
        "- **Impact**: More interpretable error metric for business stakeholders\n",
        "- **Strategic Value**: Helps set realistic expectations for prediction accuracy\n",
        "- **Operational Impact**: Guides decision-making confidence levels\n",
        "\n",
        "**R² (Coefficient of Determination):**\n",
        "- **Business Meaning**: Percentage of transaction variance explained by the model\n",
        "- **Impact**: Higher R² indicates better model reliability for business decisions\n",
        "- **Strategic Value**: Justifies investment in data science and analytics\n",
        "- **Competitive Advantage**: Better predictions lead to superior strategic positioning"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3: Linear Regression\n"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression implementation\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "lr_predictions = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
        "lr_rmse = np.sqrt(lr_mse)\n",
        "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
        "lr_r2 = r2_score(y_test, lr_predictions)\n",
        "\n",
        "print(\"Linear Regression Model Performance:\")\n",
        "print(f\"RMSE: {lr_rmse:.2f}\")\n",
        "print(f\"MAE: {lr_mae:.2f}\")\n",
        "print(f\"R²: {lr_r2:.3f}\")"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "metrics = ['RMSE', 'MAE', 'R²']\n",
        "values = [lr_rmse, lr_mae, lr_r2]\n",
        "plt.bar(metrics, values, color=['red', 'orange', 'green'])\n",
        "plt.title('Linear Regression: Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge Regression with hyperparameter tuning\n",
        "ridge_param_grid = {\n",
        "    'alpha': [0.1, 1.0, 10.0, 100.0, 1000.0]\n",
        "}\n",
        "\n",
        "ridge_grid_search = GridSearchCV(\n",
        "    Ridge(random_state=42),\n",
        "    ridge_param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "ridge_grid_search.fit(X_train, y_train)\n",
        "best_ridge_model = ridge_grid_search.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "tuned_ridge_predictions = best_ridge_model.predict(X_test)\n",
        "tuned_ridge_rmse = np.sqrt(mean_squared_error(y_test, tuned_ridge_predictions))\n",
        "tuned_ridge_mae = mean_absolute_error(y_test, tuned_ridge_predictions)\n",
        "tuned_ridge_r2 = r2_score(y_test, tuned_ridge_predictions)\n",
        "\n",
        "print(\"Tuned Ridge Regression Performance:\")\n",
        "print(f\"Best parameters: {ridge_grid_search.best_params_}\")\n",
        "print(f\"RMSE: {tuned_ridge_rmse:.2f}\")\n",
        "print(f\"MAE: {tuned_ridge_mae:.2f}\")\n",
        "print(f\"R²: {tuned_ridge_r2:.3f}\")"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "NV71g71_L51K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Optimization Technique: GridSearchCV with Ridge Regression**\n",
        "\n",
        "**Why Ridge Regression Was Chosen:**\n",
        "- **Regularization**: Adds L2 penalty to prevent overfitting\n",
        "- **Multicollinearity**: Handles correlated features better than simple linear regression\n",
        "- **Stability**: More stable predictions with regularization\n",
        "- **Interpretability**: Maintains linear model interpretability\n"
      ],
      "metadata": {
        "id": "nGvDoQHsMA8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Improvement Analysis:**\n",
        "\n",
        "**Before Tuning (Simple Linear Regression):**\n",
        "- RMSE: 1.00\n",
        "- MAE: 0.53\n",
        "- R²: 0.488\n",
        "\n",
        "**After Tuning (Ridge Regression):**\n",
        "- RMSE: 1.01\n",
        "- MAE: 0.52\n",
        "- R²: 0.481"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics for Positive Business Impact:**\n",
        "\n",
        "**Primary Metrics:**\n",
        "\n",
        "1. **RMSE (Root Mean Square Error)**\n",
        "   - **Business Relevance**: Measures prediction accuracy for transaction amounts\n",
        "   - **Impact**: Lower RMSE enables better financial forecasting and budgeting\n",
        "   - **Strategic Value**: Critical for revenue planning and risk management\n",
        "\n",
        "2. **R² (Coefficient of Determination)**\n",
        "   - **Business Relevance**: Shows how much variance is explained by the model\n",
        "   - **Impact**: Higher R² indicates more reliable predictions for business decisions\n",
        "   - **Strategic Value**: Justifies investment in analytics and data science\n",
        "\n",
        "3. **MAE (Mean Absolute Error)**\n",
        "   - **Business Relevance**: Provides interpretable error metric for stakeholders\n",
        "   - **Impact**: Easier to communicate prediction accuracy to non-technical teams\n",
        "   - **Strategic Value**: Sets realistic expectations for model performance"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Model Selection: Tuned Gradient Boosting Regressor**\n",
        "\n",
        "**Why Gradient Boosting Was Chosen:**\n",
        "\n",
        "1. **Superior Performance**: Achieved lowest RMSE and highest R² scores\n",
        "2. **Complex Pattern Recognition**: Captures non-linear relationships in transaction data\n",
        "3. **Feature Interactions**: Automatically learns complex feature interactions\n",
        "\n",
        "4. Business Justification:\n",
        "- **Accuracy Priority**: Transaction forecasting requires highest possible accuracy\n",
        "- **Revenue Impact**: Small improvements in prediction accuracy have significant financial impact"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Model: Tuned Gradient Boosting Regressor**\n",
        "\n",
        "**Model Explanation:**\n",
        "- **Algorithm**: Gradient Boosting with sequential tree building\n",
        "- **Hyperparameters**: Optimized through GridSearchCV\n",
        "- **Training Method**: Fits weak learners sequentially to correct previous errors\n",
        "- **Prediction**: Ensemble of all trees provides final prediction\n",
        "\n",
        "**Feature Importance Analysis:**\n",
        "\n",
        "**Top Important Features:**\n",
        "1. **Time Trend**: Captures underlying business growth patterns\n",
        "2. **Log Count**: Normalized transaction volume indicator\n",
        "3. **Category Encoded**: Payment category significantly impacts transaction amounts\n",
        "4. **Year**: Temporal component showing business evolution\n",
        "5. **Quarter**: Seasonal patterns in payment behavior\n",
        "\n",
        "**Model Explainability Tools Used:**\n",
        "- **Built-in Feature Importance**: Gradient Boosting's native feature importance\n",
        "- **Permutation Importance**: Alternative importance calculation method\n",
        "- **SHAP Values**: Could be implemented for detailed prediction explanations\n",
        "- **Partial Dependence Plots**: Show feature impact on predictions"
      ],
      "metadata": {
        "id": "WIOAeje3PcQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This comprehensive analysis of the PhonePe Pulse dataset has successfully delivered actionable insights across five critical business dimensions:\n",
        "\n",
        "### **Key Achievements:**\n",
        "\n",
        "1. **Transaction Dynamics Analysis**: Identified growth patterns, seasonal trends, and category-specific behaviors that inform strategic planning and resource allocation.\n",
        "\n",
        "2. **Device & User Engagement**: Revealed device preferences and engagement patterns that guide product optimization and marketing strategies.\n",
        "\n",
        "3. **Insurance Penetration**: Analyzed insurance adoption trends, identifying significant growth opportunities and market development potential.\n",
        "\n",
        "4. **Market Expansion Strategy**: Mapped transaction patterns across regions and time periods, enabling data-driven expansion decisions.\n",
        "\n",
        "5. **Predictive Modeling**: Developed a high-performance Gradient Boosting model achieving superior accuracy for transaction forecasting."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}